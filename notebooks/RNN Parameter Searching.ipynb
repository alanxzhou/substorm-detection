{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "sys.path.append('/home/alanzhou93_gmail_com/substorm-detection')\n",
    "sys.path.append('/home/alanzhou93_gmail_com/RNN')\n",
    "sys.path.append('/home/alanzhou93_gmail_com/\\baseline')\n",
    "sys.path.append('/home/alanzhou93_gmail_com/\\data')\n",
    "\n",
    "from RNN import rnn_models\n",
    "import utils\n",
    "from baseline import utils_linear\n",
    "import plot_utils\n",
    "from baseline import linear_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33424, 81, 128, 3)\n",
      "(33424, 1)\n",
      "(33443, 256, 6)\n",
      "(33424,)\n"
     ]
    }
   ],
   "source": [
    "folder = '/home/alanzhou93_gmail_com/substorm-detection/data'\n",
    "data_fn = folder + '/2classes_data128_withsw_small.npz'\n",
    "data = np.load(data_fn)\n",
    "X = data['X']\n",
    "y = data['y'][:, None]\n",
    "SW = data['SW']\n",
    "strength = data['strength']\n",
    "\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))\n",
    "print(np.shape(SW))\n",
    "print(np.shape(strength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_test_split = .2\n",
    "train_val_split = .2\n",
    "train, test = utils.split_data([X, SW, y, strength], train_test_split, random=False)\n",
    "train, val = utils.split_data(train, train_val_split, random=True, batch_size=batch_size)\n",
    "X_train, sw_train, y_train, strength_train = train\n",
    "X_val, sw_val, y_val, strength_val = val\n",
    "X_test, sw_test, y_test, strength_test = test\n",
    "\n",
    "X_train, X_val, X_test = utils.rnn_format_x([X_train, X_val, X_test])\n",
    "y_train, y_val, y_test = utils.rnn_format_y([y_train, y_val, y_test])\n",
    "\n",
    "X_train, X_val, X_test = [X_train, sw_train], [X_val, sw_val], [X_test, sw_test]\n",
    "y_train, y_val, y_test = [y_train, strength_train], [y_val, strength_val], [y_test, strength_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': batch_size,\n",
    "    'rnn_hidden_units': 64,\n",
    "    'n_stacks': 2,\n",
    "    'fc_hidden_size': 128,\n",
    "    'n_classes': 2,\n",
    "    'epochs': 1,\n",
    "    'verbose': True,\n",
    "    'time_output_weight': 1e6,\n",
    "    'rnn_type': 'GRU',\n",
    "    'output_type': 'time'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (256, 256, 6)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (256, 128, 243)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_23 (GRU)                    (256, 256, 64)       13632       input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_21 (GRU)                    (256, 128, 64)       59136       input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_24 (GRU)                    (256, 256, 64)       24768       gru_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru_22 (GRU)                    (256, 128, 64)       24768       gru_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (256, 128, 64)       0           gru_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (256, 8192)          0           gru_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (256, 8192)          0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (256, 16384)         0           flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (256, 128)           2097280     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_output (Dense)             (256, 2)             258         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,219,842\n",
      "Trainable params: 2,219,842\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 21248 samples, validate on 5120 samples\n",
      "Epoch 1/1\n",
      "21248/21248 [==============================] - 88s 4ms/step - loss: 0.7120 - acc: 0.6915 - true_positive: 0.7002 - false_positive: 0.3104 - val_loss: 0.5348 - val_acc: 0.7412 - val_true_positive: 0.7477 - val_false_positive: 0.2699\n"
     ]
    }
   ],
   "source": [
    "hist, model = rnn_models.train_functional_rnn_single(X_train, y_train, X_val, y_val, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search: RNN type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (64, 256, 6)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (64, 128, 243)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (64, 256, 32)        3744        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (64, 128, 32)        26496       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (64, 256, 32)        6240        gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (64, 128, 32)        6240        gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (64, 128, 32)        0           gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (64, 4096)           0           gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (64, 4096)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (64, 8192)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (64, 128)            1048704     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_output (Dense)             (64, 2)              258         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,091,682\n",
      "Trainable params: 1,091,682\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 21376 samples, validate on 5312 samples\n",
      "Epoch 1/10\n",
      "21376/21376 [==============================] - 324s 15ms/step - loss: 0.5693 - acc: 0.7167 - true_positive: 0.7174 - false_positive: 0.2813 - val_loss: 0.5308 - val_acc: 0.7507 - val_true_positive: 0.7613 - val_false_positive: 0.2590\n",
      "Epoch 2/10\n",
      "21376/21376 [==============================] - 318s 15ms/step - loss: 0.5158 - acc: 0.7557 - true_positive: 0.7380 - false_positive: 0.2260 - val_loss: 0.5068 - val_acc: 0.7568 - val_true_positive: 0.7610 - val_false_positive: 0.2526\n",
      "Epoch 3/10\n",
      "21376/21376 [==============================] - 316s 15ms/step - loss: 0.4768 - acc: 0.7733 - true_positive: 0.7530 - false_positive: 0.2063 - val_loss: 0.4741 - val_acc: 0.7771 - val_true_positive: 0.7257 - val_false_positive: 0.1781\n",
      "Epoch 4/10\n",
      "21376/21376 [==============================] - 317s 15ms/step - loss: 0.4561 - acc: 0.7890 - true_positive: 0.7642 - false_positive: 0.1862 - val_loss: 0.4741 - val_acc: 0.7799 - val_true_positive: 0.7936 - val_false_positive: 0.2336\n",
      "Epoch 5/10\n",
      "21376/21376 [==============================] - 317s 15ms/step - loss: 0.4367 - acc: 0.7977 - true_positive: 0.7747 - false_positive: 0.1792 - val_loss: 0.5011 - val_acc: 0.7636 - val_true_positive: 0.8329 - val_false_positive: 0.3064\n",
      "Epoch 6/10\n",
      "21376/21376 [==============================] - 317s 15ms/step - loss: 0.4149 - acc: 0.8092 - true_positive: 0.7841 - false_positive: 0.1644 - val_loss: 0.4781 - val_acc: 0.7749 - val_true_positive: 0.7738 - val_false_positive: 0.2197\n",
      "Epoch 7/10\n",
      "21376/21376 [==============================] - 317s 15ms/step - loss: 0.3960 - acc: 0.8159 - true_positive: 0.7894 - false_positive: 0.1596 - val_loss: 0.4874 - val_acc: 0.7802 - val_true_positive: 0.7742 - val_false_positive: 0.2123\n",
      "Epoch 8/10\n",
      "21376/21376 [==============================] - 316s 15ms/step - loss: 0.3815 - acc: 0.8273 - true_positive: 0.7976 - false_positive: 0.1430 - val_loss: 0.5040 - val_acc: 0.7747 - val_true_positive: 0.7268 - val_false_positive: 0.1761\n",
      "Epoch 9/10\n",
      " 7104/21376 [========>.....................] - ETA: 3:07 - loss: 0.3505 - acc: 0.8430 - true_positive: 0.8138 - false_positive: 0.1304"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-beb889c46160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     }\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_functional_rnn_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/substorm-detection/RNN/rnn_models.py\u001b[0m in \u001b[0;36mtrain_functional_rnn_single\u001b[0;34m(X_train, y_train, X_val, y_val, params)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     hist = model.fit(X_train, y_train, batch_size=params['batch_size'], epochs=params['epochs'],\n\u001b[0;32m--> 101\u001b[0;31m                      validation_data=(X_val, y_val), verbose=params['verbose'])\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist_array = []\n",
    "model_array = []\n",
    "\n",
    "for rnn_hidden_units in [32, 64, 96, 128]:\n",
    "    \n",
    "    print(rnn_hidden_units)\n",
    "    \n",
    "    params = {\n",
    "    'batch_size': batch_size,\n",
    "    'rnn_hidden_units': rnn_hidden_units,\n",
    "    'n_stacks': 2,\n",
    "    'fc_hidden_size': 128,\n",
    "    'n_classes': 2,\n",
    "    'epochs': 10,\n",
    "    'verbose': True,\n",
    "    'time_output_weight': 1e6,\n",
    "    'rnn_type': 'gru',\n",
    "    'output_type': 'time'\n",
    "    }\n",
    "    \n",
    "    hist, model = rnn_models.train_functional_rnn_single(X_train, y_train, X_val, y_val, params)\n",
    "    \n",
    "    print('Accuracy: %.2f' %hist.history['val_acc'][-1])\n",
    "    hist_array.append(hist)\n",
    "    model_array.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.figure(figsize = (10,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare separate networks to a combined network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    params = {\n",
    "    'batch_size': batch_size,\n",
    "    'rnn_hidden_units': 128,\n",
    "    'n_stacks': 2,\n",
    "    'fc_hidden_size': 128,\n",
    "    'n_classes': 2,\n",
    "    'epochs': 15,\n",
    "    'verbose': True,\n",
    "    'time_output_weight': 1e6,\n",
    "    'rnn_type': 'gru',\n",
    "    'output_type': 'time'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (256, 256, 6)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (256, 128, 243)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_7 (GRU)                     (256, 256, 128)      51840       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     (256, 128, 128)      142848      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_8 (GRU)                     (256, 256, 128)      98688       gru_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_6 (GRU)                     (256, 128, 128)      98688       gru_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (256, 128, 128)      0           gru_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (256, 16384)         0           gru_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (256, 16384)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (256, 32768)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (256, 128)           4194432     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_output (Dense)             (256, 2)             258         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "strength_output (Dense)         (256, 1)             129         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,586,883\n",
      "Trainable params: 4,586,883\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 21248 samples, validate on 5120 samples\n",
      "Epoch 1/15\n",
      "21248/21248 [==============================] - 88s 4ms/step - loss: 8188102.3554 - time_output_loss: 7.8381 - strength_output_loss: 350051.4095 - time_output_acc: 0.5010 - time_output_true_positive: 0.9838 - time_output_false_positive: 0.9812 - strength_output_mean_squared_error: 350051.4095 - strength_output_mean_absolute_error: 376.7046 - val_loss: 8237082.7750 - val_time_output_loss: 7.9712 - val_strength_output_loss: 265890.8094 - val_time_output_acc: 0.5000 - val_time_output_true_positive: 1.0000 - val_time_output_false_positive: 1.0000 - val_strength_output_mean_squared_error: 265890.8094 - val_strength_output_mean_absolute_error: 294.4933\n",
      "Epoch 2/15\n",
      "21248/21248 [==============================] - 82s 4ms/step - loss: 8193206.2470 - time_output_loss: 7.9712 - strength_output_loss: 222014.2207 - time_output_acc: 0.5000 - time_output_true_positive: 1.0000 - time_output_false_positive: 1.0000 - strength_output_mean_squared_error: 222014.2207 - strength_output_mean_absolute_error: 253.9305 - val_loss: 8184421.2500 - val_time_output_loss: 7.9712 - val_strength_output_loss: 213229.2316 - val_time_output_acc: 0.5000 - val_time_output_true_positive: 1.0000 - val_time_output_false_positive: 1.0000 - val_strength_output_mean_squared_error: 213229.2316 - val_strength_output_mean_absolute_error: 232.0906\n",
      "Epoch 3/15\n",
      "21248/21248 [==============================] - 82s 4ms/step - loss: 8166938.9819 - time_output_loss: 7.9712 - strength_output_loss: 195746.9465 - time_output_acc: 0.5000 - time_output_true_positive: 1.0000 - time_output_false_positive: 1.0000 - strength_output_mean_squared_error: 195746.9465 - strength_output_mean_absolute_error: 224.8124 - val_loss: 8168287.0750 - val_time_output_loss: 7.9712 - val_strength_output_loss: 197095.1457 - val_time_output_acc: 0.5000 - val_time_output_true_positive: 1.0000 - val_time_output_false_positive: 1.0000 - val_strength_output_mean_squared_error: 197095.1457 - val_strength_output_mean_absolute_error: 231.4324\n",
      "Epoch 4/15\n",
      "21248/21248 [==============================] - 82s 4ms/step - loss: 8155374.8434 - time_output_loss: 7.9712 - strength_output_loss: 184182.8195 - time_output_acc: 0.5000 - time_output_true_positive: 1.0000 - time_output_false_positive: 1.0000 - strength_output_mean_squared_error: 184182.8195 - strength_output_mean_absolute_error: 219.9954 - val_loss: 8156310.6000 - val_time_output_loss: 7.9712 - val_strength_output_loss: 185118.6156 - val_time_output_acc: 0.5000 - val_time_output_true_positive: 1.0000 - val_time_output_false_positive: 1.0000 - val_strength_output_mean_squared_error: 185118.6156 - val_strength_output_mean_absolute_error: 218.7750\n",
      "Epoch 5/15\n",
      "21248/21248 [==============================] - 82s 4ms/step - loss: 8143252.5843 - time_output_loss: 7.9712 - strength_output_loss: 172060.5823 - time_output_acc: 0.5000 - time_output_true_positive: 1.0000 - time_output_false_positive: 1.0000 - strength_output_mean_squared_error: 172060.5823 - strength_output_mean_absolute_error: 215.8038 - val_loss: 8143884.7750 - val_time_output_loss: 7.9712 - val_strength_output_loss: 172692.7658 - val_time_output_acc: 0.5000 - val_time_output_true_positive: 1.0000 - val_time_output_false_positive: 1.0000 - val_strength_output_mean_squared_error: 172692.7658 - val_strength_output_mean_absolute_error: 220.2158\n",
      "Epoch 6/15\n",
      "21248/21248 [==============================] - 82s 4ms/step - loss: 8139083.0120 - time_output_loss: 7.9712 - strength_output_loss: 167890.9775 - time_output_acc: 0.5000 - time_output_true_positive: 1.0000 - time_output_false_positive: 1.0000 - strength_output_mean_squared_error: 167890.9775 - strength_output_mean_absolute_error: 220.3229 - val_loss: 8139272.4500 - val_time_output_loss: 7.9712 - val_strength_output_loss: 168080.4617 - val_time_output_acc: 0.5000 - val_time_output_true_positive: 1.0000 - val_time_output_false_positive: 1.0000 - val_strength_output_mean_squared_error: 168080.4617 - val_strength_output_mean_absolute_error: 214.3697\n",
      "Epoch 7/15\n",
      "21248/21248 [==============================] - 82s 4ms/step - loss: 8127523.5843 - time_output_loss: 7.9712 - strength_output_loss: 156331.5871 - time_output_acc: 0.5000 - time_output_true_positive: 1.0000 - time_output_false_positive: 1.0000 - strength_output_mean_squared_error: 156331.5871 - strength_output_mean_absolute_error: 212.9016 - val_loss: 8121203.0250 - val_time_output_loss: 7.9712 - val_strength_output_loss: 150011.0770 - val_time_output_acc: 0.5000 - val_time_output_true_positive: 1.0000 - val_time_output_false_positive: 1.0000 - val_strength_output_mean_squared_error: 150011.0770 - val_strength_output_mean_absolute_error: 213.1749\n",
      "Epoch 8/15\n",
      "13056/21248 [=================>............] - ETA: 27s - loss: 8127269.8824 - time_output_loss: 7.9712 - strength_output_loss: 156077.8734 - time_output_acc: 0.5000 - time_output_true_positive: 1.0000 - time_output_false_positive: 1.0000 - strength_output_mean_squared_error: 156077.8734 - strength_output_mean_absolute_error: 210.9049"
     ]
    }
   ],
   "source": [
    "hist, model = rnn_models.train_functional_rnn_combined(X_train, y_train, X_val, y_val, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on only magnetometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 21248 samples, validate on 5120 samples\n",
      "Epoch 1/15\n",
      "21248/21248 [==============================] - 46s 2ms/step - loss: 0.6522 - acc: 0.6074 - true_positive: 0.5622 - false_positive: 0.3475 - val_loss: 0.6187 - val_acc: 0.6770 - val_true_positive: 0.6889 - val_false_positive: 0.3359\n",
      "Epoch 2/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.5962 - acc: 0.6919 - true_positive: 0.6810 - false_positive: 0.2967 - val_loss: 0.5861 - val_acc: 0.7027 - val_true_positive: 0.7394 - val_false_positive: 0.3350\n",
      "Epoch 3/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.5683 - acc: 0.7191 - true_positive: 0.7118 - false_positive: 0.2746 - val_loss: 0.5583 - val_acc: 0.7275 - val_true_positive: 0.6994 - val_false_positive: 0.2451\n",
      "Epoch 4/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.5421 - acc: 0.7404 - true_positive: 0.7093 - false_positive: 0.2284 - val_loss: 0.5413 - val_acc: 0.7389 - val_true_positive: 0.6934 - val_false_positive: 0.2160\n",
      "Epoch 5/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.5195 - acc: 0.7555 - true_positive: 0.7236 - false_positive: 0.2133 - val_loss: 0.5495 - val_acc: 0.7326 - val_true_positive: 0.7135 - val_false_positive: 0.2490\n",
      "Epoch 6/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.5124 - acc: 0.7628 - true_positive: 0.7232 - false_positive: 0.1984 - val_loss: 0.5386 - val_acc: 0.7354 - val_true_positive: 0.6701 - val_false_positive: 0.1999\n",
      "Epoch 7/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.4921 - acc: 0.7714 - true_positive: 0.7330 - false_positive: 0.1899 - val_loss: 0.5318 - val_acc: 0.7387 - val_true_positive: 0.6614 - val_false_positive: 0.1850\n",
      "Epoch 8/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.4864 - acc: 0.7748 - true_positive: 0.7281 - false_positive: 0.1780 - val_loss: 0.5409 - val_acc: 0.7424 - val_true_positive: 0.7195 - val_false_positive: 0.2351\n",
      "Epoch 9/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.4720 - acc: 0.7807 - true_positive: 0.7390 - false_positive: 0.1779 - val_loss: 0.5340 - val_acc: 0.7385 - val_true_positive: 0.6813 - val_false_positive: 0.2054\n",
      "Epoch 10/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.4685 - acc: 0.7837 - true_positive: 0.7475 - false_positive: 0.1816 - val_loss: 0.5306 - val_acc: 0.7482 - val_true_positive: 0.7438 - val_false_positive: 0.2470\n",
      "Epoch 11/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.4567 - acc: 0.7928 - true_positive: 0.7483 - false_positive: 0.1626 - val_loss: 0.5186 - val_acc: 0.7496 - val_true_positive: 0.6922 - val_false_positive: 0.1937\n",
      "Epoch 12/15\n",
      "21248/21248 [==============================] - 38s 2ms/step - loss: 0.4512 - acc: 0.7943 - true_positive: 0.7459 - false_positive: 0.1564 - val_loss: 0.5452 - val_acc: 0.7414 - val_true_positive: 0.7697 - val_false_positive: 0.2864\n",
      "Epoch 13/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.4366 - acc: 0.8037 - true_positive: 0.7577 - false_positive: 0.1505 - val_loss: 0.5301 - val_acc: 0.7473 - val_true_positive: 0.6692 - val_false_positive: 0.1754\n",
      "Epoch 14/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.4298 - acc: 0.8041 - true_positive: 0.7529 - false_positive: 0.1458 - val_loss: 0.5212 - val_acc: 0.7494 - val_true_positive: 0.7138 - val_false_positive: 0.2157\n",
      "Epoch 15/15\n",
      "21248/21248 [==============================] - 39s 2ms/step - loss: 0.4188 - acc: 0.8089 - true_positive: 0.7601 - false_positive: 0.1418 - val_loss: 0.5516 - val_acc: 0.7447 - val_true_positive: 0.6770 - val_false_positive: 0.1878\n"
     ]
    }
   ],
   "source": [
    "hist, model = rnn_models.train_basic_gru(X_train[0], y_train[0], X_val[0], y_val[0], params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on only solar wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21248 samples, validate on 5120 samples\n",
      "Epoch 1/15\n",
      "21248/21248 [==============================] - 67s 3ms/step - loss: 0.6536 - acc: 0.6115 - true_positive: 0.5895 - false_positive: 0.3710 - val_loss: 0.6033 - val_acc: 0.6818 - val_true_positive: 0.7315 - val_false_positive: 0.3666\n",
      "Epoch 2/15\n",
      "21248/21248 [==============================] - 67s 3ms/step - loss: 0.6057 - acc: 0.6793 - true_positive: 0.6648 - false_positive: 0.3049 - val_loss: 0.5902 - val_acc: 0.7016 - val_true_positive: 0.6411 - val_false_positive: 0.2374\n",
      "Epoch 3/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.6009 - acc: 0.6820 - true_positive: 0.6599 - false_positive: 0.2952 - val_loss: 0.5837 - val_acc: 0.6986 - val_true_positive: 0.6689 - val_false_positive: 0.2704\n",
      "Epoch 4/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5976 - acc: 0.6851 - true_positive: 0.6568 - false_positive: 0.2859 - val_loss: 0.5870 - val_acc: 0.6969 - val_true_positive: 0.6759 - val_false_positive: 0.2811\n",
      "Epoch 5/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5929 - acc: 0.6882 - true_positive: 0.6437 - false_positive: 0.2678 - val_loss: 0.5875 - val_acc: 0.6932 - val_true_positive: 0.5774 - val_false_positive: 0.1907\n",
      "Epoch 6/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5925 - acc: 0.6909 - true_positive: 0.6535 - false_positive: 0.2718 - val_loss: 0.5776 - val_acc: 0.7063 - val_true_positive: 0.7105 - val_false_positive: 0.2971\n",
      "Epoch 7/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5922 - acc: 0.6916 - true_positive: 0.6450 - false_positive: 0.2632 - val_loss: 0.5800 - val_acc: 0.6973 - val_true_positive: 0.6441 - val_false_positive: 0.2490\n",
      "Epoch 8/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5906 - acc: 0.6902 - true_positive: 0.6461 - false_positive: 0.2656 - val_loss: 0.5904 - val_acc: 0.6953 - val_true_positive: 0.5741 - val_false_positive: 0.1835\n",
      "Epoch 9/15\n",
      "21248/21248 [==============================] - 65s 3ms/step - loss: 0.5890 - acc: 0.6947 - true_positive: 0.6628 - false_positive: 0.2740 - val_loss: 0.5808 - val_acc: 0.7025 - val_true_positive: 0.7278 - val_false_positive: 0.3220\n",
      "Epoch 10/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5882 - acc: 0.6922 - true_positive: 0.6500 - false_positive: 0.2657 - val_loss: 0.5943 - val_acc: 0.6871 - val_true_positive: 0.5284 - val_false_positive: 0.1543\n",
      "Epoch 11/15\n",
      "21248/21248 [==============================] - 67s 3ms/step - loss: 0.5912 - acc: 0.6897 - true_positive: 0.6441 - false_positive: 0.2640 - val_loss: 0.5819 - val_acc: 0.7047 - val_true_positive: 0.7062 - val_false_positive: 0.2964\n",
      "Epoch 12/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5906 - acc: 0.6906 - true_positive: 0.6485 - false_positive: 0.2669 - val_loss: 0.5792 - val_acc: 0.7043 - val_true_positive: 0.6705 - val_false_positive: 0.2611\n",
      "Epoch 13/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5873 - acc: 0.6944 - true_positive: 0.6451 - false_positive: 0.2576 - val_loss: 0.5842 - val_acc: 0.6988 - val_true_positive: 0.7565 - val_false_positive: 0.3575\n",
      "Epoch 14/15\n",
      "21248/21248 [==============================] - 66s 3ms/step - loss: 0.5872 - acc: 0.6913 - true_positive: 0.6504 - false_positive: 0.2697 - val_loss: 0.5854 - val_acc: 0.6967 - val_true_positive: 0.6512 - val_false_positive: 0.2572\n",
      "Epoch 15/15\n",
      "21248/21248 [==============================] - 65s 3ms/step - loss: 0.5869 - acc: 0.6947 - true_positive: 0.6534 - false_positive: 0.2640 - val_loss: 0.5843 - val_acc: 0.7016 - val_true_positive: 0.7392 - val_false_positive: 0.3356\n"
     ]
    }
   ],
   "source": [
    "hist, model = rnn_models.train_basic_gru(X_train[1], y_train[0], X_val[1], y_val[0], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
